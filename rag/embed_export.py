# for vi data

# import json
# import os
# import time
# from dotenv import load_dotenv
# from openai import OpenAI, OpenAIError
# from openai.types import CreateEmbeddingResponse

# # === Load API Key & model ===
# load_dotenv()
# api_key = os.getenv("OPENAI_API_KEY")
# embedding_model = os.getenv("EMBEDDING_MODEL", "text-embedding-ada-002")

# client = OpenAI(api_key=api_key)

# # === C·∫•u h√¨nh ===
# INPUT_FILE = "data_vi.json"
# OUTPUT_VECTOR_FILE = "vectors_vi.json"
# OUTPUT_CHUNK_FILE = "chunks_vi.json"

# # === H√†m t·∫°o embedding ===
# def get_embedding(text: str) -> list[float]:
#     while True:
#         try:
#             response: CreateEmbeddingResponse = client.embeddings.create(
#                 input=text,
#                 model=embedding_model,
#             )
#             return response.data[0].embedding
#         except OpenAIError as e:
#             print(f"OpenAI API error: {e}")
#             return [0.0] * 1536

# # === H√†m t√°ch ƒëo·∫°n (gi·ªØ nguy√™n nh∆∞ b·∫°n vi·∫øt) ===
# def extract_chunks(data: dict) -> list[str]:
#     chunks = []
#     # [Ph·∫ßn c√≤n l·∫°i gi·ªØ nguy√™n kh√¥ng ƒë·ªïi...]
#     # Courses
#     for item in data.get("courses", []):
#         chunks.append(f"Kh√≥a h·ªçc: {item['title']}\nM√¥ t·∫£: {item['description']}")
#     # ...
#     return chunks

# # === Main ===
# if __name__ == "__main__":
#     print("üîç ƒêang t·∫£i d·ªØ li·ªáu...")
#     with open(INPUT_FILE, "r", encoding="utf-8") as f:
#         data = json.load(f)

#     chunks = extract_chunks(data)
#     print(f"üìÑ T·ªïng s·ªë ƒëo·∫°n: {len(chunks)}")

#     vectors = []
#     for i, chunk in enumerate(chunks):
#         print(f"üß† T·∫°o embedding cho ƒëo·∫°n {i + 1}/{len(chunks)}")
#         vector = get_embedding(chunk)
#         vectors.append(vector)

#     print("üíæ ƒêang l∆∞u vectors.json v√† chunks.json...")
#     with open(OUTPUT_VECTOR_FILE, "w", encoding="utf-8") as f:
#         json.dump(vectors, f)

#     with open(OUTPUT_CHUNK_FILE, "w", encoding="utf-8") as f:
#         json.dump(chunks, f, ensure_ascii=False)

#     print("‚úÖ Ho√†n t·∫•t! Vectors v√† chunks ƒë√£ ƒë∆∞·ª£c l∆∞u.")


#for en data
import json
import os
import time
from dotenv import load_dotenv
from openai import OpenAI, OpenAIError
from openai.types import CreateEmbeddingResponse

# === Load API Key & model ===
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
embedding_model = os.getenv("EMBEDDING_MODEL", "text-embedding-3-small")

client = OpenAI(api_key=api_key)

# === Config ===
INPUT_FILE = "data_en.json"
OUTPUT_VECTOR_FILE = "vectors_en.json"
OUTPUT_CHUNK_FILE = "chunks_en.json"

# === Embedding function ===
def get_embedding(text: str) -> list[float]:
    while True:
        try:
            response: CreateEmbeddingResponse = client.embeddings.create(
                input=text,
                model=embedding_model,
            )
            return response.data[0].embedding
        except OpenAIError as e:
            print(f"OpenAI API error: {e}")
            return [0.0] * 1536

# === Chunk extraction for English ===
def extract_chunks(data: dict) -> list[str]:
    chunks = []

    for item in data.get("courses", []):
        chunks.append(f"Course: {item['title']}\nDescription: {item['description']}")

    for item in data.get("faq", []):
        chunks.append(f"Q: {item['question']}\nA: {item['answer']}")

    for item in data.get("benefit", []):
        chunks.append(f"Benefit: {item['title']}\nDetails: {item['description']}")

    for office in data.get("office", []):
        chunks.append(f"Office: {office}")

    for key in ["mission", "coreValues", "practicalTraining", "registrationInstructions", "whenCompleted"]:
        if value := data.get(key):
            chunks.append(f"{key.replace('_', ' ').capitalize()}: {value}")

    for educator in data.get("educators", {}).get("educatorList", []):
        certs = ", ".join(educator.get("certificate", []))
        chunks.append(f"Educator: {educator['name']}\nCertificates: {certs}")

    for mentor in data.get("educators", {}).get("mentors", []):
        certs = ", ".join(mentor.get("certificate", []))
        chunks.append(f"Mentor: {mentor['name']}\nCertificates: {certs}")

    for feedback in data.get("studentFeedback", []):
        chunks.append(f"Student: {feedback['name']}\nFeedback: {feedback['description']}")

    if data.get("introduction"):
        chunks += data["introduction"]

    if data.get("courseRoadmap"):
        for item in data["courseRoadmap"]:
            chunks.append(f"Roadmap: {item['title']}\n{item['description']}")

    for learner in data.get("targetLearners", []):
        chunks.append(f"Target learner: {learner}")

    if fee := data.get("fee"):
        chunks.append(f"Tuition: Original price: {fee.get('OriginalPrice')}, Discounted: {fee.get('PriceReducedTo')}")

    if contact := data.get("contactInformation", {}).get("contact"):
        chunks.append("Contact info: " + ", ".join(contact))

    if other := data.get("other"):
        for item in other:
            chunks.append(f"Count: {item['quantity']} - {item['description']}")

    if name := data.get("yourName"):
        chunks.append(f"Assistant name: {name}")

    if website := data.get("website"):
        chunks.append(f"Website: {website}")

    return chunks

# === Main ===
if __name__ == "__main__":
    print("üîç Loading data...")
    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        data = json.load(f)

    chunks = extract_chunks(data)
    print(f"üìÑ Total chunks: {len(chunks)}")

    vectors = []
    for i, chunk in enumerate(chunks):
        print(f"üß† Generating embedding for chunk {i + 1}/{len(chunks)}")
        vector = get_embedding(chunk)
        vectors.append(vector)

    print("üíæ Saving vectors_en.json and chunks_en.json...")
    with open(OUTPUT_VECTOR_FILE, "w", encoding="utf-8") as f:
        json.dump(vectors, f)

    with open(OUTPUT_CHUNK_FILE, "w", encoding="utf-8") as f:
        json.dump(chunks, f, ensure_ascii=False)

    print("‚úÖ Done! English vectors and chunks saved.")
